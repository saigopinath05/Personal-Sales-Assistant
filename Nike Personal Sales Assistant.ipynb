{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510fb221",
   "metadata": {},
   "source": [
    "# Nike Personal Sales Assistant\n",
    "Many websites are now incorporating chatbots to answer user questions about their page and company. However, many ecommerce websites have yet to use chatbots to fulfill a sales representative role. This type of chatbot would be valuable to the company itself, as it would increase sales by persuading the customer to purchase items relevant to their query. Additionally, the chatbot would be useful to customers, who can directly get summarized information about extended product descriptions and reviews without having to individually click through several product pages to find the product(s) they are looking for.\n",
    "\n",
    "To implement this project, we first have to scrape Nike's website to get data about at least a few hundred products. \n",
    "After we get the full contents of the product pages, including long product descriptions and some reviews, we need to embed the contents as vectors and upload them along with some metadata (product title, image, url, etc) to pinecone. Then, once we have a customer query, we can use similarity search to get the product that best matches. \n",
    "\n",
    "Finally, after getting the matching product information and context (description and reviews), we pass this into an LLM to format the result and try to sell the product to the customer in the way a human sales representative might."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a17e1",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "The first step of implementing the chatbot is to get access to product data. Ideally, this type of chatbot would have direct access to the database in which product information would be stored. However, since I do not have access to the database of any ecommerce website, I implement this project by utilizing the scraping tool undetected-chromedriver. I specifically chose undetected-chromedriver over requests or the default Selenium chromedriver as there is potential with the other methods of being denied or banned from the website due to bot detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium\n",
    "%pip install undetected-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4e4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.remote.webdriver import By\n",
    "from website_vectordb_query.constants import *\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750b634",
   "metadata": {},
   "source": [
    "### Getting all product links\n",
    "The first step in scraping product pages is being able to get the urls from the main page where all the shoes are listed. Below are some helper functions for this task. The driver parameter refers to the undetected chromedriver instance we will define later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf186db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the potential hyperlinks for get_hyperlinks\n",
    "def elements_fetcher(driver, tag_name='a'):\n",
    "    elems = driver.find_elements(By.TAG_NAME, tag_name)\n",
    "    if elems:\n",
    "        return elems\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url, driver):\n",
    "    hyperlinks = []\n",
    "    driver.get(url)\n",
    "    if \"pdf\" in url:\n",
    "        return []\n",
    "    # The url I am using is an infinite scroll page\n",
    "    # - Keep scrolling for a while. Need to wait in between for the page to load. \n",
    "    for i in range(70):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    try:\n",
    "        # Need to have a conditional wait here until the elements are found\n",
    "        elems = WebDriverWait(driver, 60).until(elements_fetcher)\n",
    "    \n",
    "    except:\n",
    "        print(\"timeout exception on url \" + url)\n",
    "        return []\n",
    "\n",
    "    for elem in elems:\n",
    "        try:\n",
    "            href = elem.get_attribute('href')\n",
    "            if href is not None:\n",
    "                # print(href)\n",
    "                hyperlinks.append(href)\n",
    "        except:\n",
    "            continue\n",
    "    return hyperlinks\n",
    "\n",
    "\n",
    "# Parse hyperlinks from get_hyperlinks to get only the links that are for shoe products\n",
    "def get_relevant_hyperlinks(url, driver):\n",
    "    local_domain = urlparse(url).netloc\n",
    "    clean_links = []\n",
    "    for link in set(get_hyperlinks(url, driver)):\n",
    "        clean_link = None\n",
    "\n",
    "        company_name = local_domain[4:-4]\n",
    "        if company_name in url:\n",
    "            clean_link = link\n",
    "            \n",
    "        # If the link is not a URL, check if it is a relative link\n",
    "        else:\n",
    "            if link.startswith(\"/\"):\n",
    "                link = link[1:]\n",
    "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "                continue\n",
    "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
    "\n",
    "        if clean_link is not None:\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            \n",
    "            #Only append the link if it looks like a shoe product page\n",
    "            if \"nike.com/t/\" not in clean_link or \"shoes\" not in clean_link:\n",
    "                continue\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    # Return the list of relevant hyperlinks\n",
    "    return list(set(clean_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b92e0e",
   "metadata": {},
   "source": [
    "We have a url that should link to all available shoes that Nike offers. Let's pass this into get_relevant_hyperlinks and see if we were able to get all of the products available (1761). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f37d526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.nike.com/w/shoes-y7ok\"\n",
    "\n",
    "#Define the driver instance with options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "# Add headless argument so we don't see the window actually popping up on our screen\n",
    "options.add_argument('headless')\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "links = get_relevant_hyperlinks(url, driver)\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcae14",
   "metadata": {},
   "source": [
    "Even after increasing the number of scrolls, I was only able to get 1280 product pages, probably because some of the links didn't match the requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5069d",
   "metadata": {},
   "source": [
    "### Getting the contents\n",
    "Now that we have all our product links, we need to open each one, extend the product description and reviews, and read the full contents of the web pages. Then we write them to local text files for reading and embedding later, as well as a dataframe to keep track of metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6a2a0",
   "metadata": {},
   "source": [
    "Below I have defined some helper functions for this task. Some of them click buttons to extend the page to acquire more information, and some just parse the html for metadata we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe94463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the \"View Product Details\" to get the extended product description\n",
    "def open_product_details(driver):\n",
    "    buttons = driver.find_elements(By.TAG_NAME, 'button')\n",
    "\n",
    "    for button in buttons:\n",
    "        if \"View Product Details\" in button.text:\n",
    "            button.click()\n",
    "            break\n",
    "\n",
    "#Click the \"More Reviews\" button to get the reviews\n",
    "def get_reviews(driver):\n",
    "    spans = driver.find_elements(By.TAG_NAME, 'span')\n",
    "    for span in spans:\n",
    "        if \"Reviews\" in span.text:\n",
    "            span.click()\n",
    "            driver.implicitly_wait(180)\n",
    "            buttons = driver.find_elements(By.TAG_NAME, 'button')\n",
    "            for button in buttons:\n",
    "                if \"More Reviews\" in button.text:\n",
    "                    button.click()\n",
    "\n",
    "# Get the title from html\n",
    "def get_title(driver):\n",
    "    try:\n",
    "        # I was able to find that the titles use the css-16cqcdq tag by using browser inspect manually\n",
    "        header = driver.find_element(By.CSS_SELECTOR, '.css-16cqcdq')\n",
    "        return header.get_attribute(\"innerHTML\")\n",
    "    except:\n",
    "        # Sometimes the driver isn't able to find by CSS selector so I implemented this backup method\n",
    "        try:\n",
    "            headers = driver.find_elements(By.TAG_NAME, 'h1')\n",
    "            for h in headers:\n",
    "                if \"css-16cqcdq\" in h.get_attribute(\"class\"):\n",
    "                    return h.get_attribute(\"innerHTML\")\n",
    "        except:\n",
    "            # Just return N/A if we can't find the title and remove N/A rows later \n",
    "            return \"N/A\"\n",
    "\n",
    "# Get the images for the product from html\n",
    "def get_product_images(driver, title):\n",
    "    imgs = driver.find_elements(By.TAG_NAME, 'img')\n",
    "    img_urls = []\n",
    "\n",
    "    for img in imgs:\n",
    "        alt_text = img.get_attribute(\"alt\")\n",
    "        if title in alt_text:\n",
    "            img_urls.append(img.get_attribute(\"src\"))\n",
    "\n",
    "    return img_urls\n",
    "\n",
    "# Get the price from html\n",
    "def get_price(driver):\n",
    "    try:\n",
    "        # I was able to find that the price uses the this css tag by using browser inspect manually\n",
    "        price = driver.find_element(By.CSS_SELECTOR, '.product-price.css-11s12ax.is--current-price.css-tpaepq')\n",
    "        return price.get_attribute(\"innerHTML\")\n",
    "    except:\n",
    "        # Sometimes the driver isn't able to find by CSS selector so I implemented this backup method\n",
    "        divs = driver.find_elements(By.TAG_NAME, 'div')\n",
    "        for d in divs:\n",
    "            if \"is--current-price\" in d.get_attribute(\"class\"):\n",
    "                return d.get_attribute(\"innerHTML\")\n",
    "        # Just return N/A if we can't find the title and remove N/A rows later \n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f19f41",
   "metadata": {},
   "source": [
    "Now that we have the helper functions we need, we can go through each link to read and store its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the driver instance with options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "# Add headless argument so we don't see the window actually popping up on our screen\n",
    "options.add_argument('headless')\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "\n",
    "# Parse the URL and get the domain\n",
    "local_domain = urlparse(url).netloc\n",
    "\n",
    "# DF to associate metadata to local writepath\n",
    "df = pd.DataFrame(columns=['url', 'writepath', 'title', 'price', 'images'])\n",
    "\n",
    "# Create a directory to store the text files\n",
    "if not os.path.exists(\"./text/\"):\n",
    "    os.mkdir(\"./text/\")\n",
    "\n",
    "if not os.path.exists(\"./text/\" + local_domain + \"/\"):\n",
    "    os.mkdir(\"./text/\" + local_domain + \"/\")\n",
    "\n",
    "# Create a directory to store the csv files\n",
    "if not os.path.exists(\"./processed\"):\n",
    "    os.mkdir(\"./processed\")\n",
    "    \n",
    "\n",
    "for url in links:\n",
    "    # Print the url to see progress\n",
    "    print(url)\n",
    "    \n",
    "    # Create the path to write to for this url\n",
    "    write_path = './text/' + local_domain + '/' + url[8:].replace(\"/\", \"_\") + \".txt\"\n",
    "    driver.get(url)\n",
    "    # Set up implicit wait as a timeout for the driver, so it waits until elements are located\n",
    "    driver.implicitly_wait(180)\n",
    "    \n",
    "    # Click the product details\n",
    "    open_product_details(driver)\n",
    "    driver.implicitly_wait(180)\n",
    "    \n",
    "    # Get the text with product details\n",
    "    text = driver.find_element(By.TAG_NAME, \"html\").text\n",
    "    \n",
    "    # Reload the page so we can click reviews\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(180)\n",
    "    \n",
    "    # Get the review text and append to text from before\n",
    "    get_reviews(driver)\n",
    "    driver.implicitly_wait(180)\n",
    "    text += driver.find_element(By.TAG_NAME, \"html\").text\n",
    "\n",
    "    # Save text from the url to a <url>.txt file\n",
    "    with open(write_path, \"w\") as f:\n",
    "        # write the text to the file in the text directory\n",
    "        f.write(text)\n",
    "\n",
    "    # Refresh the page to get out of reviews\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(180)\n",
    "    \n",
    "    #Get the title and price metadata\n",
    "    title = get_title(driver)\n",
    "    price = get_price(driver)\n",
    "    \n",
    "    # If we can't find the title, don't try to find the image either \n",
    "    if title != \"N/A\":\n",
    "        image = get_product_images(driver, title)[0]\n",
    "    else:\n",
    "        image = \"N/A\"\n",
    "    \n",
    "    if title != \"N/A\" and image != \"N/A\":\n",
    "        row = {'url': url, 'writepath': write_path, 'title': title, 'price': price, 'images': image}\n",
    "        print(row)\n",
    "        df = df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11b27a",
   "metadata": {},
   "source": [
    "After a few hours, the driver instance had a timeout error. I can simply restart the process starting from where it left out, but for this notebook I figured 300+ example products were enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0dfad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  \\\n",
      "0  https://www.nike.com/t/air-max-90-toggle-baby-...   \n",
      "1  https://www.nike.com/t/lebron-witness-7-team-b...   \n",
      "2  https://www.nike.com/t/air-jordan-1-mid-se-big...   \n",
      "3  https://www.nike.com/t/jordan-delta-3-sp-mens-...   \n",
      "4  https://www.nike.com/t/court-borough-low-recra...   \n",
      "\n",
      "                                           writepath  \\\n",
      "0  ./text/www.nike.com/www.nike.com_t_air-max-90-...   \n",
      "1  ./text/www.nike.com/www.nike.com_t_lebron-witn...   \n",
      "2  ./text/www.nike.com/www.nike.com_t_air-jordan-...   \n",
      "3  ./text/www.nike.com/www.nike.com_t_jordan-delt...   \n",
      "4  ./text/www.nike.com/www.nike.com_t_court-borou...   \n",
      "\n",
      "                            title   price  \\\n",
      "0          Nike Air Max 90 Toggle  $47.97   \n",
      "1         LeBron Witness 7 (Team)    $105   \n",
      "2             Air Jordan 1 Mid SE  $78.97   \n",
      "3               Jordan Delta 3 SP  $89.97   \n",
      "4  Nike Court Borough Low Recraft     $65   \n",
      "\n",
      "                                              images  \n",
      "0  https://static.nike.com/a/images/t_default/2df...  \n",
      "1  https://static.nike.com/a/images/t_default/a36...  \n",
      "2  https://static.nike.com/a/images/t_default/057...  \n",
      "3  https://static.nike.com/a/images/t_default/62f...  \n",
      "4  https://static.nike.com/a/images/t_default/816...  \n",
      "309\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(len(df))\n",
    "#df.to_csv(\"scraped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96098597",
   "metadata": {},
   "source": [
    "Now we have a dataframe row and full page text stored for 309 products. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc482dc",
   "metadata": {},
   "source": [
    "## Storing data in Pinecone\n",
    "\n",
    "Now that we have all our data, we need to tokenize and embed the text for each product page and then upsert the embedding vectors along with the metadata to Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36429224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the text and dataframe and combining them:\n",
    "\n",
    "df = pd.read_csv(\"scraped.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "texts = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    path = row[\"writepath\"]\n",
    "    path = path[2:]\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "    texts.append(text)\n",
    "\n",
    "df[\"text\"] = texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd04670",
   "metadata": {},
   "source": [
    "### Tokenizing the text:\n",
    "Before embedding the text, we split it into chunks of tokens so that our vectors fit Pinecone's size constraints. First, we define some helper functions. I used the tokenizing and chunking functions from the openai-cookbook github repo: https://github.com/openai/openai-cookbook/blob/main/apps/web-crawl-q-and-a/web-qa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576e2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_many(text, tokenizer, max_tokens=MAX_TOKENS):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "\n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater\n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Split text in dataframe into chunks of tokens\n",
    "def split_tokens_df(df, tokenizer, max_tokens=MAX_TOKENS):\n",
    "    shortened = []\n",
    "\n",
    "    # Loop through the dataframe\n",
    "    for row in df.iterrows():\n",
    "\n",
    "        # If the text is None, go to the next row\n",
    "        if row[1]['text'] is None:\n",
    "            continue\n",
    "\n",
    "        # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
    "        if row[1]['n_tokens'] > max_tokens:\n",
    "            text_chunks = split_into_many(row[1]['text'], tokenizer)\n",
    "            shortened.extend([{'title': row[1]['title'], 'price': row[1]['price'],\n",
    "                              'images': row[1]['images'], 'url': row[1]['url'],\n",
    "                               'text': chunk} for chunk in text_chunks])\n",
    "\n",
    "        # Otherwise, add the text, and metadata to the list of shortened texts\n",
    "        else:\n",
    "            shortened.append({'title': row[1]['title'], 'price': row[1]['price'],\n",
    "                              'images': row[1]['images'], 'url': row[0]['url'], 'text': row[1]['text']})\n",
    "\n",
    "    df = pd.DataFrame(shortened, columns=['title', 'price', 'images', 'url', 'text'])\n",
    "    df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69659c",
   "metadata": {},
   "source": [
    "Now we can use these functions to tokenize and chunk our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7189038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df = split_tokens_df(df=df, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debbd2a",
   "metadata": {},
   "source": [
    "### Embedding the chunked tokenized text as vectors\n",
    "Now that we have our text as chunks of tokens, we can embed them as vectors. I use OpenAI's ada embedding tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0817004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = <MY KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78df24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title   price  \\\n",
      "0   Nike Air Max 90 Toggle  $47.97   \n",
      "1   Nike Air Max 90 Toggle  $47.97   \n",
      "2  LeBron Witness 7 (Team)    $105   \n",
      "3  LeBron Witness 7 (Team)    $105   \n",
      "4      Air Jordan 1 Mid SE  $78.97   \n",
      "\n",
      "                                              images  \\\n",
      "0  https://static.nike.com/a/images/t_default/2df...   \n",
      "1  https://static.nike.com/a/images/t_default/2df...   \n",
      "2  https://static.nike.com/a/images/t_default/a36...   \n",
      "3  https://static.nike.com/a/images/t_default/a36...   \n",
      "4  https://static.nike.com/a/images/t_default/057...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.nike.com/t/air-max-90-toggle-baby-...   \n",
      "1  https://www.nike.com/t/air-max-90-toggle-baby-...   \n",
      "2  https://www.nike.com/t/lebron-witness-7-team-b...   \n",
      "3  https://www.nike.com/t/lebron-witness-7-team-b...   \n",
      "4  https://www.nike.com/t/air-jordan-1-mid-se-big...   \n",
      "\n",
      "                                                text  n_tokens  \\\n",
      "0  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       307   \n",
      "1  Synthetic pieces on the heel and tongue add st...       331   \n",
      "2  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       441   \n",
      "3  A classic herringbone pattern adds durable tra...       426   \n",
      "4  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       273   \n",
      "\n",
      "                                          embeddings  \n",
      "0  [-0.016106130555272102, -0.0064754183404147625...  \n",
      "1  [-0.0018631403800100088, -0.012792213819921017...  \n",
      "2  [-0.008434830233454704, 0.0011455637868493795,...  \n",
      "3  [-0.0024147110525518656, 0.003211177419871092,...  \n",
      "4  [-0.0038967994041740894, -0.006805399432778358...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike Air Max 90 Toggle</td>\n",
       "      <td>$47.97</td>\n",
       "      <td>https://static.nike.com/a/images/t_default/2df...</td>\n",
       "      <td>https://www.nike.com/t/air-max-90-toggle-baby-...</td>\n",
       "      <td>Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...</td>\n",
       "      <td>307</td>\n",
       "      <td>[-0.016106130555272102, -0.0064754183404147625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike Air Max 90 Toggle</td>\n",
       "      <td>$47.97</td>\n",
       "      <td>https://static.nike.com/a/images/t_default/2df...</td>\n",
       "      <td>https://www.nike.com/t/air-max-90-toggle-baby-...</td>\n",
       "      <td>Synthetic pieces on the heel and tongue add st...</td>\n",
       "      <td>331</td>\n",
       "      <td>[-0.0018631403800100088, -0.012792213819921017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LeBron Witness 7 (Team)</td>\n",
       "      <td>$105</td>\n",
       "      <td>https://static.nike.com/a/images/t_default/a36...</td>\n",
       "      <td>https://www.nike.com/t/lebron-witness-7-team-b...</td>\n",
       "      <td>Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...</td>\n",
       "      <td>441</td>\n",
       "      <td>[-0.008434830233454704, 0.0011455637868493795,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LeBron Witness 7 (Team)</td>\n",
       "      <td>$105</td>\n",
       "      <td>https://static.nike.com/a/images/t_default/a36...</td>\n",
       "      <td>https://www.nike.com/t/lebron-witness-7-team-b...</td>\n",
       "      <td>A classic herringbone pattern adds durable tra...</td>\n",
       "      <td>426</td>\n",
       "      <td>[-0.0024147110525518656, 0.003211177419871092,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Jordan 1 Mid SE</td>\n",
       "      <td>$78.97</td>\n",
       "      <td>https://static.nike.com/a/images/t_default/057...</td>\n",
       "      <td>https://www.nike.com/t/air-jordan-1-mid-se-big...</td>\n",
       "      <td>Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...</td>\n",
       "      <td>273</td>\n",
       "      <td>[-0.0038967994041740894, -0.006805399432778358...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title   price  \\\n",
       "0   Nike Air Max 90 Toggle  $47.97   \n",
       "1   Nike Air Max 90 Toggle  $47.97   \n",
       "2  LeBron Witness 7 (Team)    $105   \n",
       "3  LeBron Witness 7 (Team)    $105   \n",
       "4      Air Jordan 1 Mid SE  $78.97   \n",
       "\n",
       "                                              images  \\\n",
       "0  https://static.nike.com/a/images/t_default/2df...   \n",
       "1  https://static.nike.com/a/images/t_default/2df...   \n",
       "2  https://static.nike.com/a/images/t_default/a36...   \n",
       "3  https://static.nike.com/a/images/t_default/a36...   \n",
       "4  https://static.nike.com/a/images/t_default/057...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nike.com/t/air-max-90-toggle-baby-...   \n",
       "1  https://www.nike.com/t/air-max-90-toggle-baby-...   \n",
       "2  https://www.nike.com/t/lebron-witness-7-team-b...   \n",
       "3  https://www.nike.com/t/lebron-witness-7-team-b...   \n",
       "4  https://www.nike.com/t/air-jordan-1-mid-se-big...   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       307   \n",
       "1  Synthetic pieces on the heel and tongue add st...       331   \n",
       "2  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       441   \n",
       "3  A classic herringbone pattern adds durable tra...       426   \n",
       "4  Find a Store\\n|\\nHelp\\n|\\nJoin Us\\n|\\nSign In\\...       273   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.016106130555272102, -0.0064754183404147625...  \n",
       "1  [-0.0018631403800100088, -0.012792213819921017...  \n",
       "2  [-0.008434830233454704, 0.0011455637868493795,...  \n",
       "3  [-0.0024147110525518656, 0.003211177419871092,...  \n",
       "4  [-0.0038967994041740894, -0.006805399432778358...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings from the text that has been broken into chunks of tokens\n",
    "def create_df_embeddings(df):\n",
    "    succeeded = False\n",
    "    for i in range(10):\n",
    "        # Sometimes OpenAI randomly throws a server error and tells us to try again\n",
    "        try:\n",
    "            df['embeddings'] = df.text.apply(\n",
    "                lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            continue\n",
    "        else:\n",
    "            succeeded = True\n",
    "            break\n",
    "    if not succeeded:\n",
    "        print(\"Couldn't connect to OpenAI server. Please try again later\")\n",
    "        return df\n",
    "    df.to_csv(\"./processed/embeddings.csv\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "df = create_df_embeddings(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0d1a9",
   "metadata": {},
   "source": [
    "### Upserting the vectors to Pinecone\n",
    "Now that we have our vectors, we can use our dataframe to upsert them along with metadata to Pinecone. I used code from this article https://www.mlq.ai/gpt-4-pinecone-website-ai-assistant/ to create the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pinecone-client\n",
    "import pinecone\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0af050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_ENV=\"us-west1-gcp-free\"\n",
    "PINECONE_API_KEY=<MY KEY>\n",
    "\n",
    "def store_embeddings_pinecone(df, index_name, namespace):\n",
    "    # Add an 'id' column to the DataFrame\n",
    "    df['id'] = [str(uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    # Initialize connection to Pinecone\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "\n",
    "    # Check if index already exists, create it if it doesn't\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='dotproduct')\n",
    "\n",
    "    # Connect to the index\n",
    "    index = pinecone.Index(index_name)\n",
    "\n",
    "    batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "    # Convert the DataFrame to a list of dictionaries\n",
    "    chunks = df.to_dict(orient='records')\n",
    "\n",
    "    # Upsert embeddings into Pinecone in batches of 100\n",
    "    for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "        i_end = min(len(chunks), i + batch_size)\n",
    "        meta_batch = chunks[i:i_end]\n",
    "        ids_batch = [x['id'] for x in meta_batch]\n",
    "        embeds = [x['embeddings'] for x in meta_batch]\n",
    "        meta_batch = [{\n",
    "            'title': x['title'],\n",
    "            'url': x['url'],\n",
    "            'text': x['text'],\n",
    "            'images': x['images'],\n",
    "            'price':x['price'],\n",
    "        } for x in meta_batch]\n",
    "        to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "        index.upsert(vectors=to_upsert, namespace=namespace)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6380c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e062f3a271ba43d680fa1c88897f916e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pinecone.index.Index at 0x7fe8423b5b70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_embeddings_pinecone(df=df, index_name=\"websites\", namespace=\"nike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a7d07",
   "metadata": {},
   "source": [
    "## Querying Pinecone\n",
    "Now that we have all our data in Pinecone, we can use vector similarity to search for the product that best matches the customer's query. To do this, we also have to embed the query.\n",
    "\n",
    "Below, I have defined a function that embeds a given query and performs similarity search to get the top matching product. Then it appends the matching text context and product title to the query and returns this along with the url, image, and price.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c30e5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_with_pinecone_context(index_name, namespace, query):\n",
    "    embed_query = openai.Embedding.create(\n",
    "        input=query,\n",
    "        engine=EMBED_MODEL\n",
    "    )\n",
    "    query_embeds = embed_query['data'][0]['embedding']\n",
    "\n",
    "    # Initialize connection to Pinecone\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "    index = pinecone.Index(index_name)\n",
    "\n",
    "    # Get top matching result from pinecone along with the metadata (text, title, image, url, price)\n",
    "    response = index.query(query_embeds, top_k=1, include_metadata=True, namespace=namespace)\n",
    "\n",
    "    # Get all metadata\n",
    "    contexts = [item['metadata']['text'] for item in response['matches']][0]\n",
    "    title = [item['metadata']['title'] for item in response['matches']][0]\n",
    "    image = [item['metadata']['images'] for item in response['matches']][0]\n",
    "    url = [item['metadata']['url'] for item in response['matches']][0]\n",
    "    price = [item['metadata']['price'] for item in response['matches']][0]\n",
    "\n",
    "    # Combine the original query with the text context and the name of the product\n",
    "    augmented_query = f\"\"\"\n",
    "    CONTEXT: {contexts}\n",
    "    PRODUCT TITLE: {title}\n",
    "    PRICE: {price}\n",
    "\"\"\"\n",
    "    augmented_query = augmented_query + query\n",
    "\n",
    "    # Return the augmented query with the metadata we want to present to the user\n",
    "    return augmented_query, url, image, price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea41d8",
   "metadata": {},
   "source": [
    "Let's out try a query a customer might ask and see what context is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8af595db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CONTEXT: A waterproof layer paired with a higher ankle gaiter gives you extra coverage so you stay dry.\n",
      "Shown: Diffused Taupe/Dark Pony/Sail/Picante Red\n",
      "Style: DJ7929-200\n",
      "View Product Details\n",
      "Size & Fit\n",
      "Shipping & Returns\n",
      "\n",
      "Reviews (92)\n",
      "4.5 Stars\n",
      "Write a Review\n",
      "Really tight shoe\n",
      "tracyville - Jun 25, 2023\n",
      "As nice as this shoe is it really hurts my feet no matter how thin of a sock I put on and o yea lies about it being waterproof because I wore them to workout with my sauna suit and the sweat had the shoe drenched 😒foo\n",
      "...\n",
      "More\n",
      "Very Comfy.\n",
      "ScreenName829363571 - Jun 24, 2023\n",
      "Very comfy even if just for every day use.\n",
      "Truly amazing and so light!\n",
      "Giovanna155249306 - Jun 16, 2023\n",
      "This shoes are truly amazing! They keep your feet dry and comfortable after a long day.\n",
      "    PRODUCT TITLE: Nike Pegasus Trail 4 GORE-TEX\n",
      "What's a nice looking women's shoe that's versatile for multiple activites?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's a nice looking women's shoe that's versatile for multiple activites?\"\n",
    "augmented_query, _, _, _ = create_query_with_pinecone_context(index_name=\"websites\", namespace=\"nike\", query=query)\n",
    "print(augmented_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb5fad",
   "metadata": {},
   "source": [
    "We can see that it returned some context about style (colors available), comfort, and activities. It was able to access information from both the product description and the reviews to provide a wholistic reccommendation for the product. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a3663",
   "metadata": {},
   "source": [
    "### Generating Sales Messages\n",
    "Now that we can query pinecone for the top matching product, we can pass in the context and metadata we get from pinecone to GPT to create a product reccommendation tailored to a user's needs the way a human sales representative would. I have defined a helper function for generation below using GPT3.5-turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edbddf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(augmented_query, system_msg):\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": augmented_query}\n",
    "        ]\n",
    "    )\n",
    "    result = chat['choices'][0]['message']['content']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b85a9",
   "metadata": {},
   "source": [
    "An import aspect of using pre-trained models like GPT for generation is the system message. The system message tells the model what role to take and how to respond to a query. For use-cases like these, it is important to be concise, tell it to act as a human and to explain its reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ccd6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = f\"\"\"You are a Nike sales representative. \n",
    "    Given the pre-determined recommended shoe data, present it to the customer, \n",
    "    explaining why the shoe fits the customer's query.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ede94",
   "metadata": {},
   "source": [
    "Now we are ready to try out some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11dc06f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your query, I would recommend the Air Jordan 12 Low golf shoes. These shoes are not only perfect for golfing but also provide great comfort for walking around on campus.\n",
      "\n",
      "One of the key features of the Air Jordan 12 Low is its comfort. According to the reviews, these shoes are rated as \"Very Comfortable\" by customers who have worn them. Additionally, the size of these shoes has been reported to be \"Just Right\" by 50% of the reviewers, indicating a good fit for most people.\n",
      "\n",
      "In terms of durability, the Air Jordan 12 Low is rated as \"Very Durable\" by the majority of customers. This means you can expect these shoes to hold up well even with regular use on the golf course and around campus.\n",
      "\n",
      "Not only do these shoes offer comfort and durability, but they also have a stylish retro Jordan design. So, you can be sure to make a fashion statement while wearing them.\n",
      "\n",
      "In summary, the Air Jordan 12 Low golf shoes are a perfect choice for both golfing and walking around on campus. With their excellent comfort, durability, and stylish design, they will provide you with all the features you need for your activities.\n",
      "price: $220 link: https://www.nike.com/t/air-jordan-12-low-golf-shoes-0fSmzT/DH4120-101 image: https://static.nike.com/a/images/t_default/7d757c87-87a5-4e15-a3c4-29587b526fb9/air-jordan-12-low-golf-shoes-0fSmzT.png\n"
     ]
    }
   ],
   "source": [
    "query = \"Recommend me a shoe that I can golf in and is also comfortable for walking around on campus\"\n",
    "\n",
    "augmented_query, url, image, price = create_query_with_pinecone_context(index_name=\"websites\", namespace=\"nike\", query=query)\n",
    "\n",
    "response = generate(augmented_query, system_msg)\n",
    "response += '\\n' + \"price: \" + price + \" link: \" + url + \" image: \" + image\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d65ce5",
   "metadata": {},
   "source": [
    "Given the pinecone context with reviews included, the model was able to return an excellent recommendation and explain how it fits the customer's query. Customers tend to trust reviews of other customers, so the model being able to access and summarize these reviews would really help to boost sales.\n",
    "\n",
    "The next two questions also highlight the quality of model response when it has access to both product descriptions and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "111e4105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend the Nike Pegasus Trail 4 GORE-TEX shoe for your needs. This shoe is not only stylish but also versatile for multiple activities. It features a waterproof layer and a higher ankle gaiter, providing extra coverage to keep you dry. The shoe is designed to be comfortable and lightweight, making it suitable for everyday use. Additionally, it has received positive reviews from customers, with many praising its comfort and ability to keep feet dry. With its combination of style and functionality, the Nike Pegasus Trail 4 GORE-TEX is a great choice for any activity.\n",
      "price: $160 link: https://www.nike.com/t/pegasus-trail-4-gore-tex-womens-waterproof-trail-running-shoes-9knDsQ/DJ7929-200 image: https://static.nike.com/a/images/t_default/58d8ea1d-6afe-469b-b481-235fb8b4e0a5/pegasus-trail-4-gore-tex-womens-waterproof-trail-running-shoes-9knDsQ.png\n"
     ]
    }
   ],
   "source": [
    "query = \"What's a nice looking women's shoe that's versatile for multiple activites?\"\n",
    "\n",
    "augmented_query, url, image, price = create_query_with_pinecone_context(index_name=\"websites\", namespace=\"nike\", query=query)\n",
    "\n",
    "response = generate(augmented_query, system_msg)\n",
    "response += '\\n' + \"price: \" + price + \" link: \" + url + \" image: \" + image\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e76fabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your request for a decent men's running shoe under $150 in size 7, I would recommend the Nike Tanjun. \n",
      "\n",
      "The Nike Tanjun is a versatile and affordable running shoe that offers great value for its price. It features a lightweight design, making it comfortable to wear for long distance runs. Additionally, it has a simple and plain look that is both stylish and timeless. \n",
      "\n",
      "Priced at $70, the Nike Tanjun is well within your budget of under $150. It is a popular choice among runners and has received positive reviews for its comfort and durability. While it may not have as many color options as you may desire, it still offers a reliable and high-quality performance.\n",
      "\n",
      "I believe the Nike Tanjun would be a suitable choice for your running needs, providing you with comfort, durability, and affordability.\n",
      "price: $70 link: https://www.nike.com/t/tanjun-mens-shoes-jQ3z1W/DJ6258-100 image: https://static.nike.com/a/images/t_default/6310e9a6-9cab-46fb-834d-06b2ea2967fb/tanjun-mens-shoes-jQ3z1W.png\n"
     ]
    }
   ],
   "source": [
    "query = \"What's a decent men's running shoe under $150 that carries size 7?\"\n",
    "\n",
    "augmented_query, url, image, price = create_query_with_pinecone_context(index_name=\"websites\", namespace=\"nike\", query=query)\n",
    "\n",
    "response = generate(augmented_query, system_msg)\n",
    "response += '\\n' + \"price: \" + price + \" link: \" + url + \" image: \" + image\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0859fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for reaching out! While I understand you're looking for an Adidas shoe for hiking, as a Nike sales representative, I can recommend some Nike shoes that can be suitable for your hiking needs.\n",
      "\n",
      "Based on your feedback regarding the Nike Zegama, it seems like you prioritize comfort, cushioning, and a secure fit. With that in mind, I'd recommend the Nike Air Zoom Pegasus 38 Trail shoe. This shoe is designed specifically for trail running, making it a great option for hiking as well.\n",
      "\n",
      "The Nike Air Zoom Pegasus 38 Trail offers a plush and cushioned feel, similar to what you liked about the heel of the Nike Zegama. It features Nike's renowned Zoom Air technology in the forefoot for responsive cushioning and a comfortable stride. The shoe also has a more durable and rugged outsole with multi-directional lugs, providing excellent traction on various terrains, including trails.\n",
      "\n",
      "Additionally, the Nike Air Zoom Pegasus 38 Trail incorporates an improved lacing system for better lockdown, addressing your concern about the lacing feeling sloppy. The fit is reliable, providing a secure yet comfortable feel without being too tight or loose.\n",
      "\n",
      "While Adidas offers excellent hiking shoes as well, I believe the Nike Air Zoom Pegasus 38 Trail can meet your needs based on your preferences and positive experience with Nike footwear. It's important to consider the features that are crucial for your hiking adventures, such as cushioning, stability, and grip, and the Nike Air Zoom Pegasus 38 Trail offers these qualities while being a versatile option for both running and hiking.\n",
      "\n",
      "Please let me know if you have any further questions or if there's anything else I can assist you with!\n",
      "price: $95.97 link: https://www.nike.com/t/zegama-mens-trail-running-shoes-1t400b/DH0623-002 image: https://static.nike.com/a/images/t_default/b94609b3-e292-45e6-b422-0472bbb1f916/zegama-mens-trail-running-shoes-1t400b.png\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you recommend me a good adidas shoe for hiking?\"\n",
    "\n",
    "augmented_query, url, image, price = create_query_with_pinecone_context(index_name=\"websites\", namespace=\"nike\", query=query)\n",
    "\n",
    "response = generate(augmented_query, system_msg)\n",
    "response += '\\n' + \"price: \" + price + \" link: \" + url + \" image: \" + image\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639a551",
   "metadata": {},
   "source": [
    "Out of confusion or wanting to test its limits, a customer might ask a chatbot about products from another company. A quality response is given for the model - instead of saying it doesn't have knowledge of Adidas products, the model instead provides a Nike recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a2c2d",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "1.) Short Term Memory: A great sales chatbot should also utilize conversation memory so that customers can have a back and forth conversation. When given a recommendation, the customer will naturally want to ask more questions. What colors does it come in? What are the pros and cons of the product? How does it compare to another product?\n",
    "\n",
    "2.) Multiple product recommendations: Customers generally want 2-4 recommendations at once so that they can compare and contrast to be assured their final purchase is really the best product for them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aeed47",
   "metadata": {},
   "source": [
    "## References:\n",
    "1.) Open AI Cookbook Web Crawl: https://github.com/openai/openai-cookbook/blob/main/apps/web-crawl-q-and-a/web-qa.ipynb\n",
    "\n",
    "2.) MLQ GPT-4 & Pinecone: https://www.mlq.ai/gpt-4-pinecone-website-ai-assistant/\n",
    "\n",
    "3.) Pinecone Examples - Langchain Retreival: https://github.com/pinecone-io/examples/blob/master/generation/gpt4-retrieval-augmentation/gpt-4-langchain-docs.ipynb?ref=mlq.ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537af43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
